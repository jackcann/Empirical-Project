{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a2ab41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "697f741d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " webscraping Premier League\n",
      "Scraped Premier League 2025\n",
      "Scraped Premier League 2024\n",
      "Scraped Premier League 2023\n",
      "Scraped Premier League 2022\n",
      "Scraped Premier League 2021\n",
      "Scraped Premier League 2020\n",
      "Scraped Premier League 2019\n",
      "Scraped Premier League 2018\n",
      "Scraped Premier League 2017\n",
      "Scraped Premier League 2016\n",
      "Scraped Premier League 2015\n",
      "Scraped Premier League 2014\n",
      "Scraped Premier League 2013\n",
      "Scraped Premier League 2012\n",
      "Scraped Premier League 2011\n",
      "\n",
      " webscraping La Liga\n",
      "Scraped La Liga 2025\n",
      "Scraped La Liga 2024\n",
      "Scraped La Liga 2023\n",
      "Scraped La Liga 2022\n",
      "Scraped La Liga 2021\n",
      "Scraped La Liga 2020\n",
      "Scraped La Liga 2019\n",
      "Scraped La Liga 2018\n",
      "Scraped La Liga 2017\n",
      "Scraped La Liga 2016\n",
      "Scraped La Liga 2015\n",
      "Scraped La Liga 2014\n",
      "Scraped La Liga 2013\n",
      "Scraped La Liga 2012\n",
      "Scraped La Liga 2011\n",
      "\n",
      " webscraping Serie A\n",
      "Scraped Serie A 2025\n",
      "Scraped Serie A 2024\n",
      "Scraped Serie A 2023\n",
      "Scraped Serie A 2022\n",
      "Scraped Serie A 2021\n",
      "Scraped Serie A 2020\n",
      "Scraped Serie A 2019\n",
      "Scraped Serie A 2018\n",
      "Scraped Serie A 2017\n",
      "Scraped Serie A 2016\n",
      "Scraped Serie A 2015\n",
      "Scraped Serie A 2014\n",
      "Scraped Serie A 2013\n",
      "Scraped Serie A 2012\n",
      "Scraped Serie A 2011\n",
      "\n",
      " webscraping Bundesliga\n",
      "Scraped Bundesliga 2025\n",
      "Scraped Bundesliga 2024\n",
      "Scraped Bundesliga 2023\n",
      "Scraped Bundesliga 2022\n",
      "Scraped Bundesliga 2021\n",
      "Scraped Bundesliga 2020\n",
      "Scraped Bundesliga 2019\n",
      "Scraped Bundesliga 2018\n",
      "Scraped Bundesliga 2017\n",
      "Scraped Bundesliga 2016\n",
      "Scraped Bundesliga 2015\n",
      "Scraped Bundesliga 2014\n",
      "Scraped Bundesliga 2013\n",
      "Scraped Bundesliga 2012\n",
      "Scraped Bundesliga 2011\n",
      "\n",
      " webscraping Ligue 1\n",
      "Scraped Ligue 1 2025\n",
      "Scraped Ligue 1 2024\n",
      "Scraped Ligue 1 2023\n",
      "Scraped Ligue 1 2022\n",
      "Scraped Ligue 1 2021\n",
      "Scraped Ligue 1 2020\n",
      "Scraped Ligue 1 2019\n",
      "Scraped Ligue 1 2018\n",
      "Scraped Ligue 1 2017\n",
      "Scraped Ligue 1 2016\n",
      "Scraped Ligue 1 2015\n",
      "Scraped Ligue 1 2014\n",
      "Scraped Ligue 1 2013\n",
      "Scraped Ligue 1 2012\n",
      "Scraped Ligue 1 2011\n",
      "\n",
      " Data saved\n"
     ]
    }
   ],
   "source": [
    "urls={'Premier League': 'https://fbref.com/en/comps/9/history/Premier-League-Seasons',\n",
    "    'La Liga': 'https://fbref.com/en/comps/12/history/La-Liga-Seasons',\n",
    "    'Serie A': 'https://fbref.com/en/comps/11/history/Serie-A-Seasons',\n",
    "    'Bundesliga': 'https://fbref.com/en/comps/20/history/Bundesliga-Seasons',\n",
    "    'Ligue 1': 'https://fbref.com/en/comps/13/history/Ligue-1-Seasons'}\n",
    "\n",
    "#This function gets the urls for each season from the history page\n",
    "def get_urls(history_url, season_number=15):\n",
    "    page=requests.get(history_url)\n",
    "    soup=BeautifulSoup(page.content,'html.parser')\n",
    "    table=soup.find('table')\n",
    "    urls=[]\n",
    "    \n",
    "    for row in table.find('tbody').find_all('tr'):\n",
    "        first_cell=row.find('th')\n",
    "        if first_cell and first_cell.find('a'):\n",
    "            link=first_cell.find('a')['href']\n",
    "            full_link='https://fbref.com'+link\n",
    "            urls.append(full_link)\n",
    "    \n",
    "    return urls[:season_number]\n",
    "\n",
    "#This list stores all the data retrieved\n",
    "all_data=[]\n",
    "\n",
    "#Starts from most recent season in order to later count down\n",
    "starting_year=2025\n",
    "\n",
    "for league, history_url in urls.items():\n",
    "    print(f\"\\n webscraping {league}\")\n",
    "    \n",
    "    urls=get_urls(history_url)\n",
    "    year=starting_year\n",
    "    \n",
    "    for season_url in urls:\n",
    "        try:\n",
    "            tables=pd.read_html(season_url)\n",
    "            league_table=tables[0]\n",
    "            time.sleep(random.randint(4, 8))\n",
    "\n",
    "            #Organise table\n",
    "            league_table2=league_table[['Rk', 'Squad', 'Pts', 'MP', 'Pts/MP',\n",
    "                                        'W', 'D', 'L']]\n",
    "            league_table2.columns=['Position', 'Team', 'Points', \n",
    "                                    'Matches Played', 'Points per Match',\n",
    "                                   'Wins', 'Draws', 'Losses']\n",
    "            league_table2=league_table2.dropna()\n",
    "\n",
    "            #Create league table and season year\n",
    "            league_table2['League']=league\n",
    "            league_table2['Season']=year\n",
    "\n",
    "            #Format columns\n",
    "            league_table2=league_table2[['League', 'Season', 'Position',\n",
    "                                         'Team', 'Points', 'Matches Played', \n",
    "                                         'Points per Match', 'Wins', 'Draws', 'Losses']]\n",
    "\n",
    "            all_data.append(league_table2)\n",
    "\n",
    "            print(f\"Scraped {league} {year}\")\n",
    "            #Count down the seasons\n",
    "            year-=1 \n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error in {league} {year}: {e}\")\n",
    "\n",
    "\n",
    "#Put into one dataframe\n",
    "combined_df=pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "#Create CSV\n",
    "combined_df.to_csv('data.csv', index=False)\n",
    "\n",
    "print(\"\\n Data saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8f07df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
